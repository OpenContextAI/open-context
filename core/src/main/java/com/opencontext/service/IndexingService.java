package com.opencontext.service;

import com.opencontext.dto.StructuredChunk;
import com.opencontext.entity.DocumentChunk;
import com.opencontext.entity.SourceDocument;
import com.opencontext.enums.ErrorCode;
import com.opencontext.exception.BusinessException;
import com.opencontext.repository.DocumentChunkRepository;
import com.opencontext.repository.SourceDocumentRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.*;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.client.RestTemplate;

import java.util.*;

/**
 * ì„ë² ë”©ëœ ì²­í¬ë¥¼ Elasticsearchì™€ PostgreSQLì— ì €ì¥í•˜ëŠ” ì„œë¹„ìŠ¤.
 * 
 * Elasticsearchì—ëŠ” ê²€ìƒ‰ì„ ìœ„í•œ ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼,
 * PostgreSQLì—ëŠ” ê³„ì¸µ êµ¬ì¡° ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
 */
@Slf4j
@Service
@RequiredArgsConstructor
@Transactional
public class IndexingService {

    private final DocumentChunkRepository documentChunkRepository;
    private final SourceDocumentRepository sourceDocumentRepository;
    private final RestTemplate restTemplate;

    @Value("${app.elasticsearch.url:http://localhost:9200}")
    private String elasticsearchUrl;

    @Value("${app.elasticsearch.index:document-chunks}")
    private String indexName;

    /**
     * ì„ë² ë”©ëœ ì²­í¬ë“¤ì„ Elasticsearchì™€ PostgreSQLì— ì €ì¥í•©ë‹ˆë‹¤.
     * 
     * @param documentId ë¬¸ì„œ ID
     * @param embeddedChunks ì €ì¥í•  ì„ë² ë”©ëœ ì²­í¬ ëª©ë¡
     */
    public void indexChunks(UUID documentId, List<StructuredChunk> embeddedChunks) {
        long startTime = System.currentTimeMillis();
        int totalChunks = embeddedChunks.size();
        
        log.info("ğŸ“ [INDEXING] Starting chunk indexing: documentId={}, chunks={}", documentId, totalChunks);

        try {
            // Step 1: Elasticsearchì— ë²¡í„° ë°ì´í„° ì €ì¥
            log.debug("ğŸ” [INDEXING] Step 1/2: Indexing to Elasticsearch: chunks={}", totalChunks);
            bulkIndexToElasticsearch(embeddedChunks);
            log.info("âœ… [INDEXING] Elasticsearch indexing completed: documentId={}, chunks={}", documentId, totalChunks);
            
            // Step 2: PostgreSQLì— ê³„ì¸µ êµ¬ì¡° ì •ë³´ ì €ì¥
            log.debug("ğŸ’¾ [INDEXING] Step 2/2: Saving hierarchy to PostgreSQL: chunks={}", totalChunks);
            int savedChunks = saveChunkHierarchyToPostgreSQL(documentId, embeddedChunks);
            log.info("âœ… [INDEXING] PostgreSQL hierarchy saved: documentId={}, savedChunks={}", documentId, savedChunks);
            
            long duration = System.currentTimeMillis() - startTime;
            log.info("ğŸ‰ [INDEXING] Chunk indexing completed successfully: documentId={}, chunks={}, duration={}ms", 
                    documentId, totalChunks, duration);

        } catch (Exception e) {
            long duration = System.currentTimeMillis() - startTime;
            log.error("âŒ [INDEXING] Chunk indexing failed: documentId={}, chunks={}, duration={}ms, error={}", 
                    documentId, totalChunks, duration, e.getMessage(), e);
            throw new BusinessException(ErrorCode.INDEXING_FAILED, 
                    "Failed to index chunks: " + e.getMessage());
        }
    }

    /**
     * Elasticsearchì— ì²­í¬ë“¤ì„ ë²Œí¬ ì¸ë±ì‹±í•©ë‹ˆë‹¤.
     */
    private void bulkIndexToElasticsearch(List<StructuredChunk> chunks) {
        long esStartTime = System.currentTimeMillis();
        int totalChunks = chunks.size();
        
        log.debug("ğŸ” [ELASTICSEARCH] Starting bulk indexing: chunks={}, index={}", totalChunks, indexName);

        try {
            // ë²Œí¬ ìš”ì²­ ë°”ë”” ìƒì„±
            log.debug("ğŸ“¦ [ELASTICSEARCH] Building bulk request body: chunks={}", totalChunks);
            StringBuilder bulkBody = new StringBuilder();
            
            for (StructuredChunk chunk : chunks) {
                // ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„°
                Map<String, Object> indexMeta = Map.of(
                        "index", Map.of("_id", chunk.getChunkId())
                );
                bulkBody.append(toJsonString(indexMeta)).append("\n");
                
                // ë¬¸ì„œ ë°ì´í„°
                Map<String, Object> doc = createElasticsearchDocument(chunk);
                bulkBody.append(toJsonString(doc)).append("\n");
            }

            // HTTP í—¤ë” ì„¤ì •
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.valueOf("application/x-ndjson"));

            HttpEntity<String> requestEntity = new HttpEntity<>(bulkBody.toString(), headers);

            // ë²Œí¬ API í˜¸ì¶œ
            ResponseEntity<Map<String, Object>> response = restTemplate.exchange(
                    elasticsearchUrl + "/" + indexName + "/_bulk",
                    HttpMethod.POST,
                    requestEntity,
                    (Class<Map<String, Object>>) (Class<?>) Map.class
            );

            if (response.getStatusCode() != HttpStatus.OK) {
                throw new BusinessException(ErrorCode.EXTERNAL_API_ERROR, 
                        "Elasticsearch bulk indexing failed");
            }

            // ì‘ë‹µì—ì„œ ì˜¤ë¥˜ í™•ì¸
            Map<String, Object> responseBody = response.getBody();
            if (responseBody != null && Boolean.TRUE.equals(responseBody.get("errors"))) {
                log.warn("Some documents failed to index in Elasticsearch: {}", responseBody);
            }

            long totalDuration = System.currentTimeMillis() - esStartTime;
            log.info("âœ… [ELASTICSEARCH] Bulk indexing completed successfully: chunks={}, duration={}ms", 
                    totalChunks, totalDuration);

        } catch (Exception e) {
            long totalDuration = System.currentTimeMillis() - esStartTime;
            log.error("âŒ [ELASTICSEARCH] Bulk indexing failed: chunks={}, duration={}ms, error={}", 
                    totalChunks, totalDuration, e.getMessage(), e);
            throw new BusinessException(ErrorCode.EXTERNAL_API_ERROR, 
                    "Failed to index to Elasticsearch: " + e.getMessage());
        }
    }

    /**
     * PostgreSQLì— ì²­í¬ ê³„ì¸µ êµ¬ì¡° ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
     */
    private int saveChunkHierarchyToPostgreSQL(UUID documentId, List<StructuredChunk> chunks) {
        long pgStartTime = System.currentTimeMillis();
        int totalChunks = chunks.size();
        
        log.debug("ğŸ’¾ [POSTGRESQL] Starting to save chunk hierarchy: documentId={}, chunks={}", 
                documentId, totalChunks);

        try {
            // âœ… SourceDocument ì—”í‹°í‹°ë¥¼ ê°€ì ¸ì™€ì„œ JPA ê´€ê³„ ì„¤ì •
            SourceDocument sourceDocument = sourceDocumentRepository.findById(documentId)
                    .orElseThrow(() -> new BusinessException(ErrorCode.DATABASE_ERROR, 
                            "SourceDocument not found: " + documentId));

            List<DocumentChunk> documentChunks = new ArrayList<>();

            for (StructuredChunk chunk : chunks) {
                UUID parentChunkUuid = null;
                if (chunk.getParentChunkId() != null && !chunk.getParentChunkId().trim().isEmpty()) {
                    try {
                        parentChunkUuid = UUID.fromString(chunk.getParentChunkId());
                    } catch (IllegalArgumentException e) {
                        log.warn("Invalid parent_chunk_id format: {}, skipping parent relationship for chunk: {}", 
                                chunk.getParentChunkId(), chunk.getChunkId());
                        parentChunkUuid = null;
                    }
                }

                DocumentChunk documentChunk = DocumentChunk.builder()
                        .chunkId(chunk.getChunkId())
                        .sourceDocument(sourceDocument)
                        .sourceDocumentId(documentId)
                        .title(chunk.getTitle())
                        .hierarchyLevel(chunk.getHierarchyLevel())
                        .parentChunkId(parentChunkUuid)
                        .elementType(chunk.getElementType())
                        .sequenceInDocument(0) // ê¸°ë³¸ê°’ ì„¤ì •, ì‹¤ì œë¡œëŠ” ìˆœì„œì— ë”°ë¼ ì„¤ì •í•´ì•¼ í•¨
                        .build();

                documentChunks.add(documentChunk);
            }

            // ë°°ì¹˜ ì €ì¥
            long saveStartTime = System.currentTimeMillis();
            List<DocumentChunk> savedChunks = documentChunkRepository.saveAll(documentChunks);
            long saveDuration = System.currentTimeMillis() - saveStartTime;
            
            long totalDuration = System.currentTimeMillis() - pgStartTime;
            log.info("âœ… [POSTGRESQL] Chunk hierarchy saved successfully: documentId={}, chunks={}, duration={}ms, saveTime={}ms", 
                    documentId, savedChunks.size(), totalDuration, saveDuration);
            
            return savedChunks.size();

        } catch (Exception e) {
            long totalDuration = System.currentTimeMillis() - pgStartTime;
            log.error("âŒ [POSTGRESQL] Failed to save chunk hierarchy: documentId={}, chunks={}, duration={}ms, error={}", 
                    documentId, totalChunks, totalDuration, e.getMessage(), e);
            throw new BusinessException(ErrorCode.DATABASE_ERROR, 
                    "Failed to save chunk hierarchy: " + e.getMessage());
        }
    }

    /**
     * Elasticsearch ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     */
    private Map<String, Object> createElasticsearchDocument(StructuredChunk chunk) {
        Map<String, Object> doc = new HashMap<>();
        
        doc.put("document_id", chunk.getDocumentId());
        doc.put("chunk_id", chunk.getChunkId());
        
        // âœ… content í•„ë“œ ì •ë¦¬í•˜ì—¬ ì €ì¥ (JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
        String cleanContent = sanitizeContent(chunk.getContent());
        doc.put("content", cleanContent);
        
        doc.put("title", chunk.getTitle());
        doc.put("hierarchy_level", chunk.getHierarchyLevel());
        doc.put("parent_chunk_id", chunk.getParentChunkId());
        doc.put("element_type", chunk.getElementType());
        doc.put("embedding", chunk.getEmbedding());
        doc.put("metadata", chunk.getMetadata());
        doc.put("indexed_at", new Date());

        return doc;
    }

    /**
     * content í•„ë“œì˜ Java ì½”ë“œë‚˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì •ë¦¬í•˜ì—¬ JSON íŒŒì‹± ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
     */
    private String sanitizeContent(String content) {
        if (content == null || content.trim().isEmpty()) {
            return "";
        }
        
        return content
            // Java ì½”ë“œ ê´€ë ¨ ì •ë¦¬
            .replaceAll("\\{[^}]*\\}", "")           // ì¤‘ê´„í˜¸ ë‚´ìš© ì œê±°
            .replaceAll("\\[.*?\\]", "")             // ëŒ€ê´„í˜¸ ë‚´ìš© ì œê±°
            .replaceAll("\\b(int|String|void|public|private|static|final|class|interface|extends|implements)\\b", "")  // Java í‚¤ì›Œë“œ ì œê±°
            .replaceAll("\\b(if|else|for|while|switch|case|break|continue|return|throw|try|catch|finally)\\b", "")  // Java ì œì–´ë¬¸ ì œê±°
            .replaceAll("\\b(new|this|super|null|true|false)\\b", "")  // Java ë¦¬í„°ëŸ´ ì œê±°
            
            // íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            .replaceAll("\\s+", " ")                 // ì—°ì† ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
            .replaceAll("[\\r\\n\\t]+", " ")         // ì¤„ë°”ê¿ˆ, íƒ­ì„ ê³µë°±ìœ¼ë¡œ
            .replaceAll("\\s*[;=+\\-*/%<>!&|^~]\\s*", " ")  // ì—°ì‚°ì ì£¼ë³€ ê³µë°± ì •ë¦¬
            
            // ê¸°íƒ€ ì •ë¦¬
            .replaceAll("\\s+", " ")                 // ë‹¤ì‹œ ì—°ì† ê³µë°± ì •ë¦¬
            .trim();
    }

    /**
     * ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
     * ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Jackson ObjectMapperë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
     */
    private String toJsonString(Object obj) {
        // ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ObjectMapperë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        if (obj instanceof Map) {
            Map<?, ?> map = (Map<?, ?>) obj;
            StringBuilder json = new StringBuilder("{");
            boolean first = true;
            for (Map.Entry<?, ?> entry : map.entrySet()) {
                if (!first) json.append(",");
                json.append("\"").append(entry.getKey()).append("\":");
                if (entry.getValue() instanceof String) {
                    json.append("\"").append(entry.getValue()).append("\"");
                } else if (entry.getValue() instanceof Map) {
                    json.append(toJsonString(entry.getValue()));
                } else {
                    json.append(entry.getValue());
                }
                first = false;
            }
            json.append("}");
            return json.toString();
        }
        return obj.toString();
    }
}
